import json
import requests
import random
import string
import time
import re
import math
import polars as pl
import os

try:
    from urllib.parse import parse_qs, urlencode, urlparse
except ImportError:
    from urlparse import parse_qs, urlparse
    from urllib import urlencode

from requests.packages.urllib3.exceptions import InsecureRequestWarning
requests.packages.urllib3.disable_warnings(InsecureRequestWarning)

vowels = ['a', 'e', 'i', 'o', 'u']
def vowel_count(clean_word):
    count = sum(1.0 for i in clean_word if i in vowels)
    return count / len(clean_word) if len(clean_word) > 0 else 0

class HangmanAPI(object):
    def __init__(self, access_token=None, session=None, timeout=None):
        self.hangman_url = self.determine_hangman_url()
        self.access_token = access_token
        self.session = session or requests.Session()
        self.timeout = timeout
        self.guessed_letters = []
        full_dictionary_location = "words_250000_train.txt"
        if not os.path.exists(full_dictionary_location):
            raise FileNotFoundError(f"Dictionary file {full_dictionary_location} not found. Please upload to Colab.")
        self.full_dictionary = self.build_dictionary(full_dictionary_location)
        self.df = pl.DataFrame({"word": self.full_dictionary, "length": [len(w) for w in self.full_dictionary]})
        self.letter_freq = pl.DataFrame({"letter": list(string.ascii_lowercase)}).with_columns(
            freq=pl.col("letter").map_elements(lambda l: sum(w.count(l) for w in self.full_dictionary) / sum(len(w) for w in self.full_dictionary), return_dtype=pl.Float64)
        ).sort("freq", descending=True)
        self.n_gram_dict = {n: pl.DataFrame({"ngram": [word[i:i+n] for word in self.full_dictionary if len(word) >= n for i in range(len(word) - n + 1)], "length": n}) for n in range(2, 6)}
        self.vowel_probs = self.df.group_by("length").agg(
            pl.col("word").str.extract_all(f"[{''.join(vowels)}]").list.len().alias("vowel_count")
        ).with_columns(vowel_prob=pl.col("vowel_count") / pl.col("length"))
        bigrams = [{"bigram": word[i:i+2]} for word in self.full_dictionary for i in range(len(word) - 1)]
        self.bigram_freq = pl.DataFrame(bigrams).group_by("bigram").len().sort("len", descending=True)
        self.vowel_priority = ['e', 'a', 'i', 'o', 'u']
        self.common_suffixes = ['ing', 'ed', 'es', 's']
        self.fallback_order = ['e', 'a', 'r', 'i', 'o', 't', 'n', 's', 'l', 'c', 'u', 'd', 'p', 'm', 'h', 'g', 'b', 'f', 'y', 'w', 'k', 'v', 'x', 'z', 'j', 'q']
        self.current_dictionary = []
        self.guess_count = 0

    @staticmethod
    def determine_hangman_url():
        links = ['https://trexsim.com']
        data = {link: 0 for link in links}
        for link in links:
            requests.get(link)
            for i in range(10):
                s = time.time()
                requests.get(link)
                data[link] = time.time() - s
        link = sorted(data.items(), key=lambda x: x[1])[0][0]
        link += '/trexsim/hangman'
        return link

    def guess(self, word):
        self.guess_count += 1
        clean_word = word[::2].replace("_", ".")
        len_word = len(clean_word)
        if self.guess_count == 1 and 'e' not in self.guessed_letters:
            print(f"Guess {self.guess_count}: Hardcoded guess: e")
            return 'e'
        if self.guess_count == 2 and 'a' not in self.guessed_letters:
            print(f"Guess {self.guess_count}: Hardcoded guess: a")
            return 'a'
        if self.guess_count == 3 and 'r' not in self.guessed_letters:
            print(f"Guess {self.guess_count}: Hardcoded guess: r")
            return 'r'
        current_df = pl.DataFrame({"word": self.current_dictionary or self.full_dictionary})
        pattern = clean_word.replace(".", "[a-z]")
        new_df = current_df.filter((pl.col("word").str.len_chars() == len_word) & pl.col("word").str.contains(f"^{pattern}$"))
        new_dictionary = new_df["word"].to_list()
        if len(new_dictionary) > 10000:
            new_dictionary = random.sample(new_dictionary, 10000)
        self.current_dictionary = new_dictionary
        print(f"Guess {self.guess_count}: Pattern = {clean_word}, Dictionary size = {len(new_dictionary)}, Guessed = {self.guessed_letters}, Vowel ratio = {vowel_count(clean_word):.3f}")
        if self.guess_count <= 5 and new_dictionary and vowel_count(clean_word) <= 0.55:
            vowel_df = self.vowel_probs.filter(pl.col("length") == len_word)
            if not vowel_df.is_empty():
                vowel_scores = {v: vowel_df["vowel_prob"].mean() for v in self.vowel_priority if v not in self.guessed_letters}
                if vowel_scores:
                    guess_letter = max(vowel_scores, key=vowel_scores.get)
                    print(f"Choosing vowel: {guess_letter} (prob = {vowel_scores[guess_letter]:.3f})")
                    return guess_letter
        if not new_dictionary and len_word >= 3:
            for suffix in self.common_suffixes:
                if len(suffix) <= len_word and clean_word.endswith('.' * len(suffix)):
                    suffix_pattern = '.' * (len_word - len(suffix)) + suffix
                    if self.df.filter(pl.col("word").str.contains(f"^{suffix_pattern.replace('.', '[a-z]')}$")).shape[0] > 0:
                        for letter in suffix:
                            if letter not in self.guessed_letters and not (letter in vowels and vowel_count(clean_word) > 0.55):
                                print(f"Suffix fallback: {letter} (suffix = {suffix})")
                                return letter
        if not new_dictionary:
            for n in range(5, 1, -1):
                if n <= len_word:
                    n_gram_counts = pl.DataFrame()
                    for i in range(len_word - n + 1):
                        sub_pattern = clean_word[i:i+n]
                        if '.' in sub_pattern:
                            n_gram_df = self.n_gram_dict[n].filter(pl.col("ngram").str.contains(f"^{sub_pattern.replace('.', '[a-z]')}$"))
                            if not n_gram_df.is_empty():
                                n_gram_counts = n_gram_counts.vstack(n_gram_df.select(pl.col("ngram").str.extract_all(r"[a-z]").alias("letters")))
                    if not n_gram_counts.is_empty():
                        letter_counts = n_gram_counts.explode("letters").group_by("letters").len().sort("len", descending=True)
                        for letter in letter_counts["letters"]:
                            if letter not in self.guessed_letters and not (letter in vowels and vowel_count(clean_word) > 0.55):
                                print(f"N-gram fallback (n={n}): {letter}")
                                return letter
        letter_scores = {}
        letter_freq = pl.DataFrame({"word": new_dictionary}).select(pl.col("word").str.extract_all(r"[a-z]").alias("letter")).group_by("letter").len()
        total_letters = letter_freq["len"].sum()
        bigram_boost = {}
        for i, char in enumerate(clean_word):
            if char != '.' and i < len_word - 1 and clean_word[i+1] == '.':
                next_bigrams = self.bigram_freq.filter(pl.col("bigram").str.starts_with(char))
                for bigram, count in zip(next_bigrams["bigram"], next_bigrams["len"]):
                    next_letter = bigram[1]
                    if next_letter not in self.guessed_letters:
                        bigram_boost[next_letter] = bigram_boost.get(next_letter, 0) + count
            if char != '.' and i > 0 and clean_word[i-1] == '.':
                prev_bigrams = self.bigram_freq.filter(pl.col("bigram").str.ends_with(char))
                for bigram, count in zip(prev_bigrams["bigram"], prev_bigrams["len"]):
                    prev_letter = bigram[0]
                    if prev_letter not in self.guessed_letters:
                        bigram_boost[prev_letter] = bigram_boost.get(prev_letter, 0) + count
        for letter in string.ascii_lowercase:
            if letter in self.guessed_letters or (letter in vowels and vowel_count(clean_word) > 0.55):
                continue
            pattern_counts = {}
            for dict_word in new_dictionary:
                new_pattern = list(clean_word)
                for i, char in enumerate(dict_word):
                    if char == letter and new_pattern[i] == '.':
                        new_pattern[i] = letter
                pattern = ''.join(new_pattern)
                pattern_counts[pattern] = pattern_counts.get(pattern, 0) + 1
            entropy = 0
            total_words = len(new_dictionary)
            for count in pattern_counts.values():
                prob = count / total_words
                entropy -= prob * (prob and math.log2(prob) or 0)
            freq_weight = letter_freq.filter(pl.col("letter") == letter)["len"].sum() / total_letters if total_letters > 0 else 1
            bigram_weight = bigram_boost.get(letter, 0) / sum(bigram_boost.values()) if sum(bigram_boost.values()) > 0 else 1
            letter_scores[letter] = entropy * (1 + freq_weight * 3.0 + bigram_weight * 2.0)
        if letter_scores:
            guess_letter = max(letter_scores, key=letter_scores.get)
            print(f"Information gain choice: {guess_letter}")
            return guess_letter
        for letter in self.fallback_order:
            if letter not in self.guessed_letters and not (letter in vowels and vowel_count(clean_word) > 0.55):
                print(f"Final fallback: {letter}")
                return letter
        print("Default fallback: e")
        return 'e'

    def build_dictionary(self, dictionary_file_location):
        with open(dictionary_file_location, 'r') as f:
            return f.read().splitlines()

    def start_game(self, practice=True, verbose=True):
        self.guessed_letters = []
        self.current_dictionary = self.full_dictionary
        self.guess_count = 0
        response = self.request("/new_game", {"practice": practice})
        if response.get('status') == "approved":
            game_id = response.get('game_id')
            word = response.get('word')
            tries_remains = response.get('tries_remains')
            if verbose:
                print("Successfully start a new game! Game ID: {0}. # of tries remaining: {1}. Word: {2}.".format(game_id, tries_remains, word))
            while tries_remains > 0:
                guess_letter = self.guess(word)
                self.guessed_letters.append(guess_letter)
                if verbose:
                    print("Guessing letter: {0}".format(guess_letter))
                try:
                    res = self.request("/guess_letter", {"request": "guess_letter", "game_id": game_id, "letter": guess_letter})
                except HangmanAPIError:
                    print('HangmanAPIError exception caught on request.')
                    continue
                except Exception as e:
                    print('Other exception caught on request.')
                    raise e
                if verbose:
                    print("Server response: {0}".format(res))
                status = res.get('status')
                tries_remains = res.get('tries_remains')
                if status == "success":
                    if verbose:
                        print("Successfully finished game: {0}".format(game_id))
                    return True
                elif status == "failed":
                    reason = res.get('reason', '# of tries exceeded!')
                    if verbose:
                        print("Failed game: {0}. Because of: {1}".format(game_id, reason))
                    return False
                elif status == "ongoing":
                    word = res.get('word')
        else:
            if verbose:
                print("Failed to start a new game")
        return status == "success"

    def my_status(self):
        return self.request("/my_status", {})

    def request(self, path, args=None, post_args=None, method=None):
        if args is None:
            args = dict()
        if post_args is not None:
            method = "POST"
        if self.access_token:
            if post_args and "access_token" not in post_args:
                post_args["access_token"] = self.access_token
            elif "access_token" not in args:
                args["access_token"] = self.access_token
        time.sleep(0.2)
        num_retry, time_sleep = 50, 2
        for it in range(num_retry):
            try:
                response = self.session.request(
                    method or "GET",
                    self.hangman_url + path,
                    timeout=self.timeout,
                    params=args,
                    data=post_args,
                    verify=False
                )
                break
            except requests.HTTPError as e:
                response = json.loads(e.read())
                raise HangmanAPIError(response)
            except requests.exceptions.SSLError as e:
                if it + 1 == num_retry:
                    raise
                time.sleep(time_sleep)
        headers = response.headers
        if 'json' in headers['content-type']:
            result = response.json()
        elif "access_token" in parse_qs(response.text):
            query_str = parse_qs(response.text)
            if "access_token" in query_str:
                result = {"access_token": query_str["access_token"][0]}
                if "expires" in query_str:
                    result["expires"] = query_str["expires"][0]
            else:
                raise HangmanAPIError(response.json())
        else:
            raise HangmanAPIError('Maintype was not text, or querystring')
        if result and isinstance(result, dict) and result.get("error"):
            raise HangmanAPIError(result)
        return result

class HangmanAPIError(Exception):
    def __init__(self, result):
        self.result = result
        self.code = None
        try:
            self.type = result["error_code"]
        except (KeyError, TypeError):
            self.type = ""
        try:
            self.message = result["error_description"]
        except (KeyError, TypeError):
            try:
                self.message = result["error"]["message"]
                self.code = result["error"].get("code")
                if not self.type:
                    self.type = result["error"].get("type", "")
            except (KeyError, TypeError):
                try:
                    self.message = result["error_msg"]
                except (KeyError, TypeError):
                    self.message = result
        Exception.__init__(self, self.message)

def local_test(word, target_word, max_tries=6):
    api = HangmanAPI(access_token="dummy_token", timeout=2000)
    api.guessed_letters = []
    api.current_dictionary = api.full_dictionary
    api.guess_count = 0
    clean_word = word.replace("_", ".")
    tries_remains = max_tries
    while tries_remains > 0:
        guess_letter = api.guess(word)
        api.guessed_letters.append(guess_letter)
        print(f"Guessing letter: {guess_letter}")
        new_word = list(word)
        correct_guess = False
        for i, char in enumerate(target_word):
            if char == guess_letter and word[2*i] == '_':
                new_word[2*i] = guess_letter
                correct_guess = True
        word = ''.join(new_word)
        if '_' not in word[::2]:
            print(f"Successfully guessed word: {word[::2]} (target: {target_word})")
            return True
        if not correct_guess:
            tries_remains -= 1
            print(f"Incorrect guess. Tries remaining: {tries_remains}")
        if tries_remains == 0:
            print(f"Failed to guess word: {word[::2]} (target: {target_word})")
            return False
        print(f"Current word: {word}")
    return False

# Dictionary Analysis and Testing
try:
    dictionary = load_dictionary('words_250000_train.txt')
except FileNotFoundError:
    print("Error: 'words_250000_train.txt' not found. Please upload the file to Colab.")
    raise

length_counts = pl.DataFrame({"word": dictionary}).with_columns(
    length=pl.col("word").str.len_chars()
).group_by("length").len().sort("length")
print("Word length distribution:")
for row in length_counts.iter_rows():
    length, count = row
    print(f"Length {length}: {count} words ({count/len(dictionary)*100:.2f}%)")

letter_counts = pl.DataFrame({"letter": list("".join(dictionary))}).group_by("letter").len().sort("len", descending=True)
print("\nLetter frequencies:")
for row in letter_counts.iter_rows():
    letter, count = row
    print(f"{letter}: {count} occurrences ({count/sum(letter_counts['len'])*100:.2f}%)")

# Local Testing with 300 Words
short_words = [w for w in dictionary if 1 <= len(w) <= 4]
rare_words = [w for w in dictionary if any(c in w for c in 'qjzx')]
other_words = [w for w in dictionary if w not in short_words and w not in rare_words]
test_words = (random.sample(short_words, min(150, len(short_words))) +
              random.sample(rare_words, min(30, len(rare_words))) +
              random.sample(other_words, 120))

successes = 0
failed_games = []
print("\nRunning 300 local test games...")
for i, word in enumerate(test_words, 1):
    print(f"\nTest game {i}: Target word = {word}, Length = {len(word)}")
    word_pattern = ' '.join('_' * len(word))
    success = local_test(word_pattern, word)
    if success:
        successes += 1
    else:
        failed_games.append((word, word_pattern))
    if i % 50 == 0:
        print(f"Progress: {i}/300 games, Current success rate: {successes/i:.3f}")

local_success_rate = successes / 300
print(f"\nLocal test completed. Ran 300 games. Success rate: {local_success_rate:.3f}")
if failed_games:
    print("\nSample failed games:")
    for word, pattern in failed_games[:3]:
        print(f"Failed word: {word}, Initial pattern: {pattern}")

# Server Testing (commented out to preserve token)
"""
api = HangmanAPI(access_token="NEW_TOKEN", timeout=2000)
for i in range(50):
    print(f'Playing practice game {i+1}')
    api.start_game(practice=1, verbose=True)
    time.sleep(0.5)
[total_practice_runs, total_recorded_runs, total_recorded_successes, total_practice_successes] = api.my_status()
practice_success_rate = total_practice_successes / total_practice_runs if total_practice_runs > 0 else 0
print(f'Ran {total_practice_runs} practice games. Success rate: {practice_success_rate:.3f}')
"""